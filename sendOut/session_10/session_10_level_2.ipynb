{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "european-northeast",
   "metadata": {},
   "source": [
    "# Session 10\n",
    "## Introduction\n",
    "Today we're going to build:\n",
    "\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Ridge Regression \n",
    "- Naive Bayes \n",
    "\n",
    "using health related data. Struecture codes will be provided. Along the way, we'll play with some fun Python codes. By the end, we'll have a complete model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-loading",
   "metadata": {},
   "source": [
    "**Please make sure the downloaded data are in the same folder as listed in the drive so that the data loading process will go smoothly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-selling",
   "metadata": {},
   "source": [
    "In **introduction**, you will work with a simplified sBP dataset that have been consolidated into one```'TXT'``` file available in the data folder as ```'dataset1.txt'```. Specifically, your goal will be to use this data to predict the systolic blood pressure (sBP) of a patient based on the patient's age. \n",
    "\n",
    "Since the target variable here is quantitative, this is a regression problem. To begin, we will start with simplest case. You will fit a simple linear regression with just one feature: ```age```. To make the introduction easy to understand, we will not split train and test data but focus more on the model fitting part.\n",
    "\n",
    "Before that, however, you need to import the data and get it into the form needed by scikit-learn. This involves creating feature and target variable arrays. Furthermore, since you are going to use only one feature to begin with, you need to do some reshaping using NumPy's ```.reshape()``` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-hartford",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-connectivity",
   "metadata": {},
   "source": [
    "**In the first cell we are going to import packages and classes.\n",
    "It is a good habit to install packages at the beginning of the codes, but for illustration purpose, we import packages at the beginning of each section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Model building\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from matplotlib import style\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "# import statsmodels.api as sm\n",
    "\n",
    "from termcolor import colored as cl\n",
    "# Split train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load model package\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Display the plot in notebook and make plots sorted\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-receptor",
   "metadata": {},
   "source": [
    "### Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data to data folder\n",
    "health_df_1 = pd.read_csv('./data/dataset1.txt', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-heading",
   "metadata": {},
   "source": [
    "To check what is the data type for load-in data, we can use type() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(health_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-court",
   "metadata": {},
   "source": [
    "**To double check whether table501.txt has been loaded succesfully and have a brief view on the data. Always list part of the data and check if they make sense.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataframe\n",
    "health_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-cutting",
   "metadata": {},
   "source": [
    "We will need to extract X and Y from the dataset by making a subset of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X (SBP) and Y (Age)\n",
    "X = health_df_1.SBP\n",
    "# print(X)\n",
    "# To extract colum by colum index\n",
    "# X = health_df_1.iloc[:,0]\n",
    "# print(X)\n",
    "Y = health_df_1.Age\n",
    "\n",
    "print(\"Before any preprocessing, the shape of X array is:\", X.shape)\n",
    "# Call .reshape() on x because this array is required to be two-dimensional\n",
    "# For more information about the reshape function:\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\n",
    "X = X.to_numpy().reshape(-1, 1)\n",
    "\n",
    "print(\"Before reshaping, the shape of X array is:\", X.shape)\n",
    "Y = Y.to_numpy()\n",
    "print(\"The shape of Y array is:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-bermuda",
   "metadata": {},
   "source": [
    "### Exploring the data (data visualization)\n",
    "As always, it is important to explore your data before building models. \n",
    "\n",
    "#### Histogram\n",
    "Histogram helps us to have a brief idea of the data distribution and monitor outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram with normal curve\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "# Use funtion matplotlib.pyplot.hist(x, alpha=n)to plot histogram\n",
    "# For more infomation:\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "n, bins, patches = plt.hist(x=X, # Dataset to be visualized\n",
    "                            bins='auto', # Automatically \n",
    "                            color='#0504aa', # We chose a specific color here\n",
    "                            alpha=0.7, # Transparency\n",
    "                            rwidth=0.85) # the bin width in display\n",
    "plt.grid(axis='y', alpha=0.75) # Set the distance between horizontal lines and display the horizontal lines\n",
    "plt.xlabel('SBP') # Label name in the x-axis\n",
    "plt.ylabel('Count') # Label name in the y-axis\n",
    "plt.title('Histogram of SBP')# Title name of the main plot\n",
    "plt.show() # Show the plot in Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-tobago",
   "metadata": {},
   "source": [
    "#### Scatter plot\n",
    "While histogram helps us to have an insight about the distribution of the data, scatter plot helps us to better understand the relationship and overall trend between dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot to further visualice the relationship between\n",
    "# SBP and Age\n",
    "plt.style.use('seaborn-whitegrid') # Grid setting\n",
    "plt.scatter(X, Y, color='#0504aa') # Same as the histogram function above cells, but this one creates a scatter plot\n",
    "plt.xlabel('SBP')\n",
    "plt.ylabel('Age')\n",
    "plt.title('Scatter plot of SBP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-somalia",
   "metadata": {},
   "source": [
    "As you can see, there is a strongly positive correlation, so a linear regression should be able to capture this trend. Your job is to fit a linear regression and then predict the life expectancy, overlaying these predicted values on the plot to generate a regression line. You will also compute and print the $R^2$ score using sckit-learn's ```.score()``` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-chester",
   "metadata": {},
   "source": [
    "#### Model building\n",
    "LinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built linear regression model\n",
    "# Create model class. Currently the model has not been fitted yet.\n",
    "slr_model = LinearRegression()\n",
    "# Fit the model\n",
    "slr_model.fit(X, Y)\n",
    "# When we want to retrive some information in the fitted model\n",
    "# we can use model_name.variableToBeRetrived_\n",
    "intercept = slr_model.intercept_\n",
    "slope = slr_model.coef_\n",
    "print('intercept:', intercept)\n",
    "print('slope:', slope)\n",
    "# When we want to use the fitted model for prediction\n",
    "# use the model_name.predict(test_data) function\n",
    "y_pred = slr_model.predict(X)\n",
    "# print('predicted response:', y_pred, sep='\\n')\n",
    "y_pred = intercept + slope * X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-decision",
   "metadata": {},
   "source": [
    "- red dots: predicted value\n",
    "- blue dots: original data\n",
    "- red line: fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression\n",
    "plt.xlabel('SBP', fontsize=15)\n",
    "plt.ylabel('Age', fontsize=15)\n",
    "# Prediction\n",
    "plt.scatter(X, Y)\n",
    "plt.scatter(X, y_pred)\n",
    "plt.plot(X, y_pred, c = 'r', linewidth=5, alpha=.5, solid_capstyle='round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-toolbox",
   "metadata": {},
   "source": [
    "### Choose an evaluation metric\n",
    "* We then need to compare these predictions with the actual result and measure them in some way.\n",
    "* This is where the selection of evaluation metric is important. For regression, we measure the distance between the predicted and actual answers in some way. The shorter the distance, the more correct the model is. \n",
    "* We cover three common metrics below:\n",
    "  * `Mean Absolute Error`: which provides a mean score for all the predicted versus actual values as an absolute value \n",
    "  * `Means Squared Error`: which provides a mean score for all the predicted versus actual values as a square of the absolute value\n",
    "  * `R2`: the proportion of the variance in the dependent variable that is predictable from the independent variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the value of MSE \n",
    "MSE = mean_squared_error(Y, y_pred)\n",
    "print('MSE:', MSE)\n",
    "# Obtain the value of MAE \n",
    "MAE = mean_absolute_error(Y, y_pred)\n",
    "print('MAE:', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To output the p-value for feature\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-ticket",
   "metadata": {},
   "source": [
    "A p-value is a measure of the probability that an observed difference could have occurred just by random chance. The lower the p-value, the greater the statistical significance of the observed difference.\n",
    "\n",
    "AIC: https://en.wikipedia.org/wiki/Akaike_information_criterion\n",
    "\n",
    "BIC: https://en.wikipedia.org/wiki/Bayesian_information_criterion\n",
    "\n",
    "Statsmodels (a statistics package in Python): https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "slm = sm.OLS(Y, X)\n",
    "fitted_slm = slm.fit()\n",
    "print(fitted_slm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-recall",
   "metadata": {},
   "source": [
    "## Part 1: Multiple linear regression\n",
    "\n",
    "In **Part 1**, you will work with a slightly more complicated clinical dataset that have been consolidated into one ```'CSV'``` file available in the data folder as ```'smoke.csv'```. Specifically, your goal will be to use this data to predict the effect of mother’s smoking during pregnancy (pack/day) and mother’s age at childbirth (years) on birth weight of their infants (oz).\n",
    "\n",
    "In this section, you will learn how to examin the basic statistics and visualize the relationship between independent variables and split the dataset into ```train``` and ```test``` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "health_df_2 = pd.read_csv('./data/smoke.csv')\n",
    "# View data structure\n",
    "health_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has a lot of functionality to assist with exploratory data analysis\n",
    "# .describe() provide summary statistics on all numeric columns\n",
    "print(health_df_2.describe())\n",
    "# Similarly, you can also use this function df_name.info()\n",
    "print(health_df_2.info())\n",
    "# we can also see the shape of the data\n",
    "print(\"\\n The shape of dataset 2 is:\", health_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictors and labels from the dataset\n",
    "X = health_df_2[['Mother_age', 'Mother_smoking']]\n",
    "Y = health_df_2['Birth_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id is not needed in training/prediction process\n",
    "# To simplify the dataset you can drop this column\n",
    "df_2 = health_df_2.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-enemy",
   "metadata": {},
   "source": [
    "### Pair plot \n",
    "A pairs plot allows us to see both distribution of single variables and relationships between two variables. Pair plots are a great method to identify trends for follow-up analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the pairplot of variables\n",
    "# Set grid\n",
    "style.use('seaborn-whitegrid')\n",
    "# Set figure size\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "# Specify dataset to used\n",
    "sns.pairplot(df_2)\n",
    "# You can also save the plot\n",
    "plt.savefig('pairplor_health_df_2.png')\n",
    "# Display the generated plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-arrangement",
   "metadata": {},
   "source": [
    "### Train/test split for regression\n",
    "Train and test sets are vital to ensure that your supervised learning model is able to generalize well to new data. This was true for classification models, and is equally true for linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into trianing and validation\n",
    "X = df_2.drop(\"Birth_weight\", axis = 1)\n",
    "Y = df_2[\"Birth_weight\"]\n",
    "# Set random seed here so that you will get the same result as solution\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-waters",
   "metadata": {},
   "source": [
    "Reference for LinearRegression()\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time!\n",
    "# Please call the model objec in the below line, and name the model as mlr\n",
    "mlr = \n",
    "# Fit the model with training data\n",
    "\n",
    "# Call model prediction on test data\n",
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time!\n",
    "# Evaluate mlr model\n",
    "# Obtain the value of R square on test data\n",
    "print(cl(\"R-Squared :\", attrs = [\"bold\"]),\n",
    "      mlr.score(X_test.to_numpy(),\n",
    "                y_test))\n",
    "# Obtain the value of MSE \n",
    "MSE = \n",
    "print(cl(\"MSE:\", attrs = [\"bold\"]), MSE)\n",
    "# Obtain the value of MAE \n",
    "MAE =\n",
    "print(cl(\"MAE:\", attrs = [\"bold\"]), MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-amber",
   "metadata": {},
   "source": [
    "We then need to fit the model by calling the OLS object’s fit() method. Ignore the warning about the kurtosis test if it appears, we have only 16 examples in our dataset and the test of the kurtosis is valid only if there are more than 20 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time!\n",
    "# View how many samples we have in the training set (threr is more than one solution to this question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = sm.OLS(y_train, X_train)\n",
    "fitted_mlm = mlm.fit()\n",
    "print(fitted_mlm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-loading",
   "metadata": {},
   "source": [
    "## Part 2: Binary Logistic Regression\n",
    "This part is modified from Harvard CS109A's lab 6 notebook:\n",
    "https://harvard-iacs.github.io/2018-CS109A/labs/lab-6/student/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-valuation",
   "metadata": {},
   "source": [
    "Linear regression is usually a good baseline model, but since the outcome we're trying to predict only takes values 0 and 1 we'll want to use logistic regression instead of basic linear regression.\n",
    "\n",
    "In this section, you will use the clinical dataset from Ille-et-Vilaine Study of Oesophageal Cancer\n",
    "- Cases: 200 men with oesophageal cancer (OC)\n",
    "- Controls: 775 OC-free men randomly drawn from the same regions.\n",
    "- Primary Interest: To assess associations between alcohol and tobacco consumptions and oesophageal cancer incidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model package\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in and checking\n",
    "oesophageal_df = pd.read_csv(\"data/oesophageal.csv\", index_col=0)\n",
    "# Please examine the first 6 rows of the dataset use method in previous \n",
    "# data checking process\n",
    "oesophageal_df.head() # Leave this line blank for exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please view the dataset summary matrix with the method in previous \n",
    "# data checking process\n",
    "oesophageal_df.describe() # Leave this line blank for exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-diabetes",
   "metadata": {},
   "source": [
    "### Split train and test sets \n",
    "reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into trianing and validation\n",
    "# Time to practise! Please separate the read-in data\n",
    "# into training and testing sets\n",
    "X = oesophageal_df.drop(\"case\", axis = 1) # Leave this line blank for exercise\n",
    "Y = oesophageal_df[\"case\"] # Leave this line blank for exercise\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) # Leave this line blank for exercise\n",
    "# Double check whether you have successfully \n",
    "# separate training and testing sets\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your training data\n",
    "# Leave following cell blank for exercise\n",
    "style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "sns.pairplot(X_train)\n",
    "plt.savefig('pairplor_oesophageal_df_X_train.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-optimization",
   "metadata": {},
   "source": [
    "**Model building part**\n",
    "Logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‘lbfgs’ solver handles multinomial loss in multiclass problems \n",
    "# The “balanced” mode uses the values of y to automatically adjust\n",
    "# weights inversely proportional to class frequencies in the input \n",
    "# data as n_samples / (n_classes * np.bincount(y))\n",
    "logreg_model = LogisticRegression(class_weight=\"balanced\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_train = logreg_model.predict(X_train)\n",
    "y_preds_test = logreg_model.predict(X_test)\n",
    "\n",
    "full_logreg_score_train = accuracy_score(y_train, y_preds_train)\n",
    "full_logreg_score_test = accuracy_score(y_test, y_preds_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Training Set Score: {}'.format(full_logreg_score_train))\n",
    "print('Test Set Score: {}'.format(full_logreg_score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-jordan",
   "metadata": {},
   "source": [
    "#### We will use a build-in function to calculate precision, recall vs thresholds\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probs_y is a 2-D array of the probabilities of \n",
    "# class 0 (first column of array) vs class 1 (2nd column in array)\n",
    "probs_y = logreg_model.predict_proba(X_test)\n",
    "# Retrieve probability of being 1(in second column of probs_y)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs_y[:, 1]) \n",
    "# Similar as plots in above sections\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "# Plot dash lines\n",
    "plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n",
    "plt.ylabel(\"Precision, Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "# Specify legend location and size\n",
    "plt.legend(loc=\"lower left\",fontsize = \"large\")\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"AUC:\", pr_auc)\n",
    "# Similar as plots in above sections\n",
    "# plt.title(\"AUC vs Threshold Chart\")\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.title(\"F1 vs Threshold Chart\")\n",
    "# Plot lines\n",
    "plt.plot(thresholds, F1[:-1], label=\"F1\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-formula",
   "metadata": {},
   "source": [
    "## Part 3: Ridge Regression\n",
    "Ridge regression is a regression technique that is quite similar to unadorned least squares linear regression: simply adding an $\\ell_2$ **penalty** on the parameters $\\beta$ to the objective function for linear regression yields the objective function for ridge regression.\n",
    "\n",
    "Our goal is to find an assignment to $\\beta$ that minimizes the function\n",
    "\n",
    "$$f(\\beta) = \\|X\\beta - Y\\|_2^2 + \\lambda \\|\\beta\\|_2^2,$$\n",
    "\n",
    "where $\\lambda$ is a hyperparameter and, as usual, $X$ is the training data and $Y$ the observations. In practice, we tune $\\lambda$ until we find a model that generalizes well to the test data.\n",
    "\n",
    "In this section, you will work with Gapminder data that we have consolidated into one CSV file available in the workspace as 'gapminder.csv'. Specifically, your goal will be to use this data to predict the life expectancy in a given country based on features such as the country's GDP, fertility rate, and population. As in Chapter 1, the dataset has been preproces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For k-fold cv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "# Load model\n",
    "from sklearn.linear_model import Ridge\n",
    "# Cross validation\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "gm_df = pd.read_pickle(\"./data/gm_2008.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-contribution",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "The dataset may contain a few unknown values. If that is the case, we can use dataset.dropna() function to do data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num of na before cleaning: \", gm_df.isna().sum())\n",
    "gm_df = gm_df.drop(labels=['Region'], axis='columns')\n",
    "print(\"num of na after cleaning: \", gm_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-communication",
   "metadata": {},
   "source": [
    "To create a cleaner dataset, we will drop some columns and remove NaN values manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a subdataset based on the previous one\n",
    "# Split the data set into trianing and validation\n",
    "X = gm_df.drop('life', axis='columns').values\n",
    "y = gm_df['life'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-burden",
   "metadata": {},
   "source": [
    "A test set should still be held out for final evaluation. \n",
    "\n",
    "- A model is trained only using the folds labeled as training data;\n",
    "\n",
    "- The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='https://scikit-learn.org/stable/_images/grid_search_cross_validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create this function to plot alpha with the error range\n",
    "# don't need to understand\n",
    "def display_plot(cv_scores, cv_scores_std, alpha_space):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "    # Try to uncomment this line to see the change of the final plot\n",
    "#     ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title('CV Score and std error region vs Alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-nepal",
   "metadata": {},
   "source": [
    "Here the defualt score of the cv score is R square value.\n",
    "Scores can also be specified with different evaluation metrics.\n",
    "For classification task, it has different default score metrics. \n",
    "\n",
    "But overally, the higher the score, the better the model.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to test different range of alpha \n",
    "# alpha_space = [1e-3, 1e-2, 3e-2, 5e-2, 1e-1, 1, 3, 5, 10]\n",
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "# Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "    \n",
    "    # Specify the alpha value to use: ridge.alhpa\n",
    "    ridge.alpha = alpha\n",
    "    \n",
    "    # Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, X_train, y_train, cv=10)\n",
    "    \n",
    "    # Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    \n",
    "    # Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "    \n",
    "# Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std, alpha_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time!\n",
    "# Let's try with some different value of alphas\n",
    "# and try to outperform alpha = 0.6\n",
    "alpha = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-oasis",
   "metadata": {},
   "source": [
    "Reference for Ridge regression:https:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "Reference for Lasso regression:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ridge regression model\n",
    "ridge_model = Ridge(normalize=True)\n",
    "ridge_model.alpha = 0.6\n",
    "# Fit the model\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "y_pred = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-priest",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the value of MSE \n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', MSE)\n",
    "# Obtain the value of MAE \n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', MAE)\n",
    "R2 = ridge_model.score(X_test, y_test)\n",
    "print(\"R2:\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-questionnaire",
   "metadata": {},
   "source": [
    "## Part 4: Naive Bayes and optional exercise\n",
    "reference:\n",
    "\n",
    "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.05-Naive-Bayes.ipynb#scrollTo=-NJHDvC9xpc-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset stimulation package\n",
    "from sklearn.datasets import make_blobs\n",
    "# Model package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Decision boundary\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-harvard",
   "metadata": {},
   "source": [
    "Now we will implement the model on clinical data. In this dataset, we are trying to predic whether the patient have diabetes based on the patient's glucose level and bloodpressure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df = pd.read_csv(\"./data/NB_dataset.txt\", delimiter=',')\n",
    "nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: try to view the summary table for this dataset\n",
    "\n",
    "# Solution:\n",
    "print(nb_df.describe())\n",
    "print(nb_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-garden",
   "metadata": {},
   "source": [
    "Before feeding the data to the naive Bayes classifier model, we need to do some pre-processing.\n",
    "Here, we’ll create the x and y variables by taking them from the dataset and using the train_test_split function of scikit-learn to split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nb_df[[\"glucose\", \"bloodpressure\"]]\n",
    "y = nb_df[\"diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: try to split the dataset into training and validation set with \n",
    "# test_size = 0.25 and random_sate = 1\n",
    "\n",
    "# Solution:\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-monkey",
   "metadata": {},
   "source": [
    "**Model Evaluation**\n",
    "\n",
    "Finally, we need to check to see how well our model is performing on the test data. For this, we evaluate our model by finding the accuracy score produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)*100\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Avoid using variables with the same name as a function\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_value = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-yukon",
   "metadata": {},
   "source": [
    "**Optional Exercise:**\n",
    "\n",
    "- Use the population dataset that we used in Ridge regression section\n",
    "- We will try to do some feature selection based on the information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into trianing and validation\n",
    "# Time to practise! Please separate the read-in data\n",
    "# into training and testing sets\n",
    "X = gm_df.drop('life', axis='columns').values\n",
    "# Change continuous labels to binary labels\n",
    "gm_df['life'] = np.where(gm_df.life > 65, 1, 0)\n",
    "y = gm_df['life'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # Leave this line blank for exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "# Dimensional purpose\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)*100\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Avoid using variables with the same name as a function\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_value = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-cookie",
   "metadata": {},
   "source": [
    "The model has a bad AUC and accuracy values. We will try to improve the prediction by doing some feature selection based on the training set and use only a subset of important variables as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-melbourne",
   "metadata": {},
   "source": [
    "Sklearn has the function \"mutual_info_classif\" that can be used to calculate information gain, similar to what we have seen in lecture. More information on the implementation of this can be found at:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see which features we have so far\n",
    "gm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the information gain for each feature in the data set\n",
    "information = mutual_info_classif(X_train, y_train)\n",
    "features_name = ['population', 'fertility', 'HIV', 'CO2', 'BMI_male', 'GDP', 'child_mortality']\n",
    "information_gain = dict(zip(information, features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the dictionary we just created, with the most significant features first\n",
    "for i in sorted(information_gain, reverse = True):\n",
    "    print(str(i) + \": \" + str(information_gain[i]))\n",
    "# Print the number of features in the dictionary, so that we can verify that there are\n",
    "# as many features in the dictionary as we selected when we created the 'used_features' array\n",
    "print(len(information_gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature index from the original dataset\n",
    "selected_features = ['child_mortality','fertility', 'BMI_male', 'GDP', 'HIV', 'CO2']\n",
    "feature_index_list = []\n",
    "for feature in selected_features:\n",
    "    feature_index = gm_df.columns.get_loc(feature)\n",
    "    feature_index_list.append(feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the original dataset\n",
    "X_train = X_train[:, 1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performce the same operation on the test dataset\n",
    "X_test = X_test[:, 1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)*100\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Avoid using variables with the same name as a function\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_value = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", \"%.0f%%\" % accuracy)\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
