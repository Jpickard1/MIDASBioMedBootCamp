{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 15 Decision trees\n",
    "> Reference:https://github.com/goodboychan/goodboychan.github.io/blob/master/_notebooks/2020-06-03-01-Decision-tree-for-classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "# Cross valudation\n",
    "from sklearn.model_selection import cross_validate\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "# Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree for classification\n",
    "- Classification-tree\n",
    "    - Sequence of if-else questions about individual features\n",
    "    - **Objective**: infer class labels\n",
    "    - Able to caputre non-linear relationships between features and labels\n",
    "    - Don't require feature scaling(e.g. Standardization)\n",
    "- Decision Regions\n",
    "    - Decision region: region in the feature space where all instances are assigned to one class label\n",
    "    - Decision Boundary: surface separating different decision regions\n",
    "![decision region](image/decision_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your first classification tree\n",
    "In this exercise you'll work with the **Wisconsin Breast Cancer Dataset** from the UCI machine learning repository. You'll predict whether a tumor is malignant or benign based on two features: the mean radius of the tumor (```radius_mean```) and its mean number of concave points (```concave points_mean```).\n",
    "\n",
    "Reference of dataset:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "-  ID number\n",
    "-  Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry\n",
    "- fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "cancer_dataset = pd.read_csv('./data/wbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first 5 rows of the dataset\n",
    "cancer_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of available variables in the dataset and their data types\n",
    "cancer_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We notice that the label in this dadtaset has a data type as object. We will pay attention to that and do some transfermation when building the label array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the dataset\n",
    "cancer_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the decision boundary in 2-d space, we will play with a toy example of \n",
    "# two features first\n",
    "X_2d = cancer_dataset[['radius_mean', 'concave points_mean']]\n",
    "# Try to add more features that will increase the predictivity of the model\n",
    "# X = cancer_dataset[['radius_mean', 'concave points_mean', 'area_mean', 'smoothness_mean', 'compactness_mean']]\n",
    "y = cancer_dataset['diagnosis']\n",
    "print(\"labels before transfermation: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer characters into binary number\n",
    "y = y.map({'M':1, 'B':0})\n",
    "print(\"labels after transfermation: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of diseased examples\n",
    "malignant = len(y[y == 1])\n",
    "# Cound the number of not diseased examples\n",
    "benign = len(y[y == 0])\n",
    "\n",
    "# Print out the counts of each class\n",
    "print(\"Milagnant: \", malignant, \", percentage: \", malignant/(malignant+benign))\n",
    "print(\"Benign: \", benign, \", percentage: \", benign/(malignant+benign))\n",
    "print(\"Total: \", str(malignant+benign))\n",
    "\n",
    "# Make a Pie chart to represent how many example we have in each class\n",
    "plt.pie([malignant, benign], labels=['Maligant', 'Benign'], startangle=90)\n",
    "plt.title('Percent for each Example Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2d, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: \n",
    "\n",
    "- more information about DecisionTreeClassifier in scikit-learn: [(help)](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "- about scoring metrics: [(help)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "\n",
    "**Notes**\n",
    "\n",
    "The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to **fully grown and unpruned trees** which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "min_impurity_decreasefloat, default=0.0\n",
    "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "max_depthint, default=None\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "# decision_tree_model = DecisionTreeClassifier(max_depth=6, random_state=1, min_samples_leaf = 2, criterion = \"entropy\")\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=6, random_state=1, min_samples_leaf = 2, criterion = \"gini\")\n",
    "# decision_tree_model = DecisionTreeClassifier(max_depth=, random_state=1, min_samples_leaf = , criterion = \"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation\n",
    "scoring = [\"f1\", \"accuracy\", \"roc_auc\"]\n",
    "# Change X_2d to X if you add more features as input\n",
    "scores = cross_validate(decision_tree_model, X_2d, y, cv=5, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores is a dictionary which follows the format {\"key\":item}\n",
    "# key is the name for the item, item stores the value (can be a string or number)\n",
    "# print(scores)\n",
    "print(scores.keys())\n",
    "print(scores.values())\n",
    "# print(scores.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information about average fit time, f1, test accuracy (validation accuracy)\n",
    "# and roc_auc here\n",
    "avg_fit_time = np.mean(scores[\"fit_time\"])\n",
    "std_fit_time = np.std(scores[\"fit_time\"])\n",
    "\n",
    "avg_test_f1 = np.mean(scores[\"test_f1\"])\n",
    "std_test_f1 = np.std(scores[\"test_f1\"])\n",
    "\n",
    "avg_test_accuracy = np.mean(scores[\"test_accuracy\"])\n",
    "std_test_accuracy = np.std(scores[\"test_accuracy\"])\n",
    "\n",
    "avg_test_roc_auc = np.mean(scores[\"test_roc_auc\"])\n",
    "std_test_roc_auc = np.std(scores[\"test_roc_auc\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"avg_fit_time\", avg_fit_time)\n",
    "print(\"std_fit_time\", std_fit_time)\n",
    "\n",
    "print(\"avg_test_f1\", avg_test_f1)\n",
    "print(\"std_test_f1\", std_test_f1)\n",
    "\n",
    "print(\"avg_test_accuracy\", avg_test_accuracy)\n",
    "print(\"std_test_accuracy\", std_test_accuracy)\n",
    "\n",
    "print(\"avg_test_roc_auc\", avg_test_roc_auc)\n",
    "print(\"std_test_roc_auc\", std_test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dt to the training set\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classification tree\n",
    "Now that you've fit your first classification tree, it's time to evaluate its performance on the test set. You'll do so using the accuracy metric which corresponds to the fraction of correct predictions made on the test set.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set labels\n",
    "y_pred = decision_tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.8f}\".format(acc))\n",
    "# Compute test set auc\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "auc_value = metrics.auc(fpr, tpr)\n",
    "print(\"Test set auc: {:.8f}\".format(auc_value))\n",
    "# Compute test set f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Test set f1: {:.8f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after k-fold cross validation, we can select a decision trees model with parameters that has the best performance among the ones you have testd. Let's build another logistic regression model following the codes in Tuesday's lab and make a comparison among those models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression vs classification tree\n",
    "A classification tree divides the feature space into rectangular regions. In contrast, a linear model such as logistic regression produces only a single linear decision boundary dividing the feature space into two decision regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize model result in 2-d space using the following function,\n",
    "# please make sure the input for X is two dimensial.\n",
    "def plot_labeled_decision_regions(X,y, models):\n",
    "    '''Function producing a scatter plot of the instances contained \n",
    "    in the 2D dataset (X,y) along with the decision \n",
    "    regions of two trained classification models contained in the\n",
    "    list 'models'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas DataFrame corresponding to two numerical features \n",
    "    y: pandas Series corresponding the class labels\n",
    "    models: list containing two trained classifiers \n",
    "    \n",
    "    '''\n",
    "    # Organize plots in the output space\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10.0, 5), sharey=True)\n",
    "    # i represent the index of the model list, \n",
    "    # model represent the model object\n",
    "    for i, model in enumerate(models):\n",
    "        # this is a build-in fuction to visualize the decision boundary of classification models\n",
    "        # with 2 legends, ax specify the subfigure's location in the whole figure \n",
    "        plot_decision_regions(X.values, y.values, model, legend= 2, ax = ax[i])\n",
    "        # Give a title to the plot by fitting in the model's name\n",
    "        ax[i].set_title(model.__class__.__name__)\n",
    "        # label the x_axis of the subplot\n",
    "        ax[i].set_xlabel(X.columns[0])\n",
    "        # We only want to set the label for y axis once \n",
    "        # the second plot will follow the scale of x axis/y aixs of the first plot\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(X.columns[1])\n",
    "            ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
    "            ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
    "    # display a tight layout\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate logistic regression\n",
    "logistic_regression = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logistic regression to the training set\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called model_list containing the two classifiers logreg and dt\n",
    "# rename the model\n",
    "model_list = [logistic_regression, decision_tree_model]\n",
    "\n",
    "# Review the decision regions of the two classifier\n",
    "plot_labeled_decision_regions(X_test, y_test, model_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
